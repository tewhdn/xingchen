// api/chat.js (Vercelä¸“ç”¨æ ¼å¼)
import express from 'express';
import cors from 'cors';
import OpenAI from 'openai';

const app = express();

// ä¸­é—´ä»¶é…ç½®
app.use(cors({
  origin: '*',
  methods: ['POST', 'OPTIONS'],
  allowedHeaders: ['Content-Type']
}));

app.use(express.json());

const deepseek = new OpenAI({
  baseURL: 'https://api.deepseek.com',
  apiKey: process.env.DEEPSEEK_API_KEY
});

const VALID_MODELS = ['deepseek-chat', 'deepseek-reasoner'];

// Vercel Serverless Functionå…¥å£
export default async (req, res) => {
  // å¤„ç†é¢„æ£€è¯·æ±‚
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  try {
    const { model = 'deepseek-chat', messages } = req.body;

    if (!VALID_MODELS.includes(model)) {
      return res.status(400).json({
        error: 'æ— æ•ˆçš„æ˜Ÿè½¨æ¨¡å¼',
        validModels: VALID_MODELS
      });
    }

    const completion = await deepseek.chat.completions.create({
      model,
      messages: [{
        role: "system",
        content: `ï¼ˆ${model === 'deepseek-reasoner' ? 'æ˜Ÿæ²³æ¨æ¼”' : 'æ˜Ÿæµ·æ¼«æ¸¸'}æ¨¡å¼å¯åŠ¨ï¼‰`
      }, ...messages],
      temperature: 0.7,
      max_tokens: 2000
    });

    res.json({ choices: completion.choices });
  } catch (error) {
    console.error('ğŸŒŒæ˜Ÿè½¨å¼‚å¸¸:', error);
    res.status(500).json({
      error: {
        code: error.code || 'QUANTUM_DISRUPTION',
        message: error.message
      }
    });
  }
};
